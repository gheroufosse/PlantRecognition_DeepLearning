{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec3aec04",
   "metadata": {},
   "source": [
    "# Plant Disease Detection Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cc1aab",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4a487065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 78;\n                var nbb_unformatted_code = \"# General\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\";\n                var nbb_formatted_code = \"# General\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4e51cb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 79;\n                var nbb_unformatted_code = \"# Torch\\nimport torch\\nfrom torchvision import datasets, transforms, models  # datsets  , transforms\\nfrom torch.utils.data.sampler import SubsetRandomSampler\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nfrom datetime import datetime\";\n                var nbb_formatted_code = \"# Torch\\nimport torch\\nfrom torchvision import datasets, transforms, models  # datsets  , transforms\\nfrom torch.utils.data.sampler import SubsetRandomSampler\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nfrom datetime import datetime\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Torch\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models  # datsets  , transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b4c61c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 80;\n                var nbb_unformatted_code = \"# A simple extension for Jupyter Notebook and Jupyter Lab to beautify Python code automatically using Black.\\n%load_ext nb_black\";\n                var nbb_formatted_code = \"# A simple extension for Jupyter Notebook and Jupyter Lab to beautify Python code automatically using Black.\\n%load_ext nb_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A simple extension for Jupyter Notebook and Jupyter Lab to beautify Python code automatically using Black.\n",
    "%load_ext nb_black\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f7d38",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac47dfcd",
   "metadata": {},
   "source": [
    "Transforms are used for Data Augmentation like cropping the image, resize the image, convert the image to tensor, rotate the image, and many more. Transforms work as a filter for all images. We are using the following code to transform the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "31b119ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 81;\n                var nbb_unformatted_code = \"transform = transforms.Compose(\\n    [transforms.Resize(255), \\n     transforms.RandomCrop(224,10),\\n     transforms.ToTensor()]\\n)\";\n                var nbb_formatted_code = \"transform = transforms.Compose(\\n    [transforms.Resize(255), transforms.RandomCrop(224, 10), transforms.ToTensor()]\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(255), \n",
    "     transforms.RandomCrop(224,10),\n",
    "     transforms.ToTensor()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "525dfa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 82;\n                var nbb_unformatted_code = \"dataset = datasets.ImageFolder(\\n    \\\"Plant_leave_diseases_dataset_with_augmentation\\\", transform=transform)\";\n                var nbb_formatted_code = \"dataset = datasets.ImageFolder(\\n    \\\"Plant_leave_diseases_dataset_with_augmentation\\\", transform=transform\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "    \"Plant_leave_diseases_dataset_with_augmentation\", transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "11c54d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 61468\n",
       "    Root location: Plant_leave_diseases_dataset_with_augmentation\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=255, interpolation=bilinear, max_size=None, antialias=None)\n",
       "               RandomCrop(size=(224, 224), padding=10)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 83;\n                var nbb_unformatted_code = \"dataset\";\n                var nbb_formatted_code = \"dataset\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf9555",
   "metadata": {},
   "source": [
    "## Split into Train and Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e467fb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train size :36572\n",
      "length of validation size :15675\n",
      "length of test size :24896\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 84;\n                var nbb_unformatted_code = \"indices = list(range(len(dataset)))\\nsplit = int(np.floor(0.85 * len(dataset)))  # train_size\\nvalidation = int(np.floor(0.70 * split))  # validation\\n#print(0, validation, split, len(dataset))\\nprint(f\\\"length of train size :{validation}\\\")\\nprint(f\\\"length of validation size :{split - validation}\\\")\\nprint(f\\\"length of test size :{len(dataset)-validation}\\\")\";\n                var nbb_formatted_code = \"indices = list(range(len(dataset)))\\nsplit = int(np.floor(0.85 * len(dataset)))  # train_size\\nvalidation = int(np.floor(0.70 * split))  # validation\\n# print(0, validation, split, len(dataset))\\nprint(f\\\"length of train size :{validation}\\\")\\nprint(f\\\"length of validation size :{split - validation}\\\")\\nprint(f\\\"length of test size :{len(dataset)-validation}\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = list(range(len(dataset)))\n",
    "split = int(np.floor(0.85 * len(dataset)))  # train_size\n",
    "validation = int(np.floor(0.70 * split))  # validation\n",
    "#print(0, validation, split, len(dataset))\n",
    "print(f\"length of train size :{validation}\")\n",
    "print(f\"length of validation size :{split - validation}\")\n",
    "print(f\"length of test size :{len(dataset)-validation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506d5af0",
   "metadata": {},
   "source": [
    "Like this, we use ~60% for training and ~40% for testing.\n",
    "About validation data :\n",
    "\n",
    "If you want to build a solid model you have to follow that specific protocol of splitting your data into three sets: One for training, one for validation and one for final evaluation, which is the test set.\n",
    "\n",
    "The idea is that you train on your training data and tune your model with the results of metrics (accuracy, loss etc) that you get from your validation set.\n",
    "\n",
    "Your model doesn't \"see\" your validation set and isn't in any way trained on it, but you as the architect and master of the hyperparameters tune the model according to this data. Therefore it indirectly influences your model because it directly influences your design decisions. You nudge your model to work well with the validation data and that can possibly bring in a tilt.\n",
    "\n",
    "Exactly that is the reason you only evaluate your model's final score on data that neither your model nor you yourself has used – and that is the third chunk of data, your test set.\n",
    "\n",
    "Only this procedure makes sure you get an unaffected view of your models quality and ability to generalize what is has learned on totally unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8f08c303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 85;\n                var nbb_unformatted_code = \"# randomize the choice of test, train and validation images\\nnp.random.shuffle(indices)\";\n                var nbb_formatted_code = \"# randomize the choice of test, train and validation images\\nnp.random.shuffle(indices)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# randomize the choice of test, train and validation images\n",
    "np.random.shuffle(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "31766736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 86;\n                var nbb_unformatted_code = \"train_indices, validation_indices, test_indices = (\\n    indices[:validation],\\n    indices[validation:split],\\n    indices[split:],\\n)\";\n                var nbb_formatted_code = \"train_indices, validation_indices, test_indices = (\\n    indices[:validation],\\n    indices[validation:split],\\n    indices[split:],\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_indices, validation_indices, test_indices = (\n",
    "    indices[:validation],\n",
    "    indices[validation:split],\n",
    "    indices[split:],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed72ffc",
   "metadata": {},
   "source": [
    "Here in the above code we first getting indices and then split the data into train , test and validation data. Total 36584 for train , 15679 for validaiton and remaining images for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b3fe22ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 87;\n                var nbb_unformatted_code = \"train_sampler = SubsetRandomSampler(train_indices)\\nvalidation_sampler = SubsetRandomSampler(validation_indices)\\ntest_sampler = SubsetRandomSampler(test_indices)\";\n                var nbb_formatted_code = \"train_sampler = SubsetRandomSampler(train_indices)\\nvalidation_sampler = SubsetRandomSampler(validation_indices)\\ntest_sampler = SubsetRandomSampler(test_indices)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "validation_sampler = SubsetRandomSampler(validation_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741f87df",
   "metadata": {},
   "source": [
    "SubsetRandomSampler is used to sample our data. Here we are creating an object of SubsetRandomSampler Object and later we will use this sampler in train data loader and test data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "08eb8385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 88;\n                var nbb_unformatted_code = \"targets_size = len(dataset.class_to_idx)\";\n                var nbb_formatted_code = \"targets_size = len(dataset.class_to_idx)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets_size = len(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db510ff9",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf26f17",
   "metadata": {},
   "source": [
    "Convolution Aithmetic Equation : (W - F + 2P) / S + 1\n",
    "W = Input Size\n",
    "F = Filter Size\n",
    "P = Padding Size\n",
    "S = Stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8d3ebf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CropDetectCNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=25088, out_features=39, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 89;\n                var nbb_unformatted_code = \"class CropDetectCNN(nn.Module):\\n    # initialize the class and the parameters\\n    def __init__(self):\\n        super(CropDetectCNN, self).__init__()\\n\\n        # convolutional layer 1 & max pool layer 1\\n        self.layer1 = nn.Sequential(\\n            nn.Conv2d(3, 16, kernel_size=3),\\n            nn.MaxPool2d(kernel_size=2))\\n\\n        # convolutional layer 2 & max pool layer 2\\n        self.layer2 = nn.Sequential(\\n            nn.Conv2d(16, 32, kernel_size=3, padding=1, stride=2),\\n            nn.MaxPool2d(kernel_size=2))\\n\\n        #Fully connected layer\\n        self.fc = nn.Linear(32*28*28, 39)\\n        \\n        \\n\\n    # Feed forward the network\\n    def forward(self, x):\\n        out = self.layer1(x)\\n        out = self.layer2(out)\\n        out = out.reshape(out.size(0), -1)\\n        out = self.fc(out)\\n        return out\\n\\n\\nmodel = CropDetectCNN()\\nprint(model)\";\n                var nbb_formatted_code = \"class CropDetectCNN(nn.Module):\\n    # initialize the class and the parameters\\n    def __init__(self):\\n        super(CropDetectCNN, self).__init__()\\n\\n        # convolutional layer 1 & max pool layer 1\\n        self.layer1 = nn.Sequential(\\n            nn.Conv2d(3, 16, kernel_size=3), nn.MaxPool2d(kernel_size=2)\\n        )\\n\\n        # convolutional layer 2 & max pool layer 2\\n        self.layer2 = nn.Sequential(\\n            nn.Conv2d(16, 32, kernel_size=3, padding=1, stride=2),\\n            nn.MaxPool2d(kernel_size=2),\\n        )\\n\\n        # Fully connected layer\\n        self.fc = nn.Linear(32 * 28 * 28, 39)\\n\\n    # Feed forward the network\\n    def forward(self, x):\\n        out = self.layer1(x)\\n        out = self.layer2(out)\\n        out = out.reshape(out.size(0), -1)\\n        out = self.fc(out)\\n        return out\\n\\n\\nmodel = CropDetectCNN()\\nprint(model)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CropDetectCNN(nn.Module):\n",
    "    # initialize the class and the parameters\n",
    "    def __init__(self):\n",
    "        super(CropDetectCNN, self).__init__()\n",
    "\n",
    "        # convolutional layer 1 & max pool layer 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        # convolutional layer 2 & max pool layer 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1, stride=2),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        #Fully connected layer\n",
    "        self.fc = nn.Linear(32*28*28, 39)\n",
    "        \n",
    "        \n",
    "\n",
    "    # Feed forward the network\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = CropDetectCNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "698a1719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 90;\n                var nbb_unformatted_code = \"device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\nprint(device)\";\n                var nbb_formatted_code = \"device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\nprint(device)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cb6f9d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 91;\n                var nbb_unformatted_code = \"#model = CNN(targets_size)\";\n                var nbb_formatted_code = \"# model = CNN(targets_size)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model = CNN(targets_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6b2f76a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CropDetectCNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=25088, out_features=39, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 92;\n                var nbb_unformatted_code = \"model.to(device)\";\n                var nbb_formatted_code = \"model.to(device)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "aa104c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 222, 222]             448\n",
      "         MaxPool2d-2         [-1, 16, 111, 111]               0\n",
      "            Conv2d-3           [-1, 32, 56, 56]           4,640\n",
      "         MaxPool2d-4           [-1, 32, 28, 28]               0\n",
      "            Linear-5                   [-1, 39]         978,471\n",
      "================================================================\n",
      "Total params: 983,559\n",
      "Trainable params: 983,559\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 8.48\n",
      "Params size (MB): 3.75\n",
      "Estimated Total Size (MB): 12.80\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 93;\n                var nbb_unformatted_code = \"from torchsummary import summary\\n\\nsummary(model, (3, 224, 224))\";\n                var nbb_formatted_code = \"from torchsummary import summary\\n\\nsummary(model, (3, 224, 224))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9f002a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 94;\n                var nbb_unformatted_code = \"criterion = nn.CrossEntropyLoss()  # this include softmax => No + cross entropy loss\\noptimizer = torch.optim.Adam(model.parameters())\";\n                var nbb_formatted_code = \"criterion = nn.CrossEntropyLoss()  # this include softmax => No + cross entropy loss\\noptimizer = torch.optim.Adam(model.parameters())\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # this include softmax => No + cross entropy loss\n",
    "optimizer = torch.optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77007061",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "73a6e459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 95;\n                var nbb_unformatted_code = \"def batch_gd(model, criterion, train_loader, validation_loader, epochs):\\n    train_losses = np.zeros(epochs)\\n    validation_losses = np.zeros(epochs)\\n    \\n    for e in range(epochs):\\n        t0 = datetime.now()\\n        train_loss = []\\n        model.train()\\n        for inputs, targets in train_loader:\\n            inputs, targets = inputs.to(device), targets.to(device)\\n\\n            optimizer.zero_grad()\\n\\n            output = model(inputs)\\n\\n            loss = criterion(output, targets)\\n\\n            train_loss.append(loss.item())  # torch to numpy world\\n\\n            loss.backward()\\n            optimizer.step()\\n            \\n        \\n        train_loss = np.mean(train_loss)\\n\\n        validation_loss = []\\n\\n        for inputs, targets in validation_loader:\\n            \\n            model.eval()\\n            \\n            with torch.no_grad():\\n\\n                inputs, targets = inputs.to(device), targets.to(device)\\n\\n                output = model(inputs)\\n\\n                loss = criterion(output, targets)\\n\\n                validation_loss.append(loss.item())  # torch to numpy world\\n        \\n        \\n        \\n        validation_loss = np.mean(validation_loss)\\n\\n        train_losses[e] = train_loss\\n        validation_losses[e] = validation_loss\\n\\n        dt = datetime.now() - t0\\n\\n        print(\\n            f\\\"Epoch : {e+1}/{epochs} Train_loss: {train_loss:.3f} Validation_loss: {validation_loss:.3f} Duration: {dt}\\\"\\n        )\\n\\n    return train_losses, validation_losses\\n #accuracy += torch.mean(equals.type(torch.FloatTensor))\";\n                var nbb_formatted_code = \"def batch_gd(model, criterion, train_loader, validation_loader, epochs):\\n    train_losses = np.zeros(epochs)\\n    validation_losses = np.zeros(epochs)\\n\\n    for e in range(epochs):\\n        t0 = datetime.now()\\n        train_loss = []\\n        model.train()\\n        for inputs, targets in train_loader:\\n            inputs, targets = inputs.to(device), targets.to(device)\\n\\n            optimizer.zero_grad()\\n\\n            output = model(inputs)\\n\\n            loss = criterion(output, targets)\\n\\n            train_loss.append(loss.item())  # torch to numpy world\\n\\n            loss.backward()\\n            optimizer.step()\\n\\n        train_loss = np.mean(train_loss)\\n\\n        validation_loss = []\\n\\n        for inputs, targets in validation_loader:\\n\\n            model.eval()\\n\\n            with torch.no_grad():\\n\\n                inputs, targets = inputs.to(device), targets.to(device)\\n\\n                output = model(inputs)\\n\\n                loss = criterion(output, targets)\\n\\n                validation_loss.append(loss.item())  # torch to numpy world\\n\\n        validation_loss = np.mean(validation_loss)\\n\\n        train_losses[e] = train_loss\\n        validation_losses[e] = validation_loss\\n\\n        dt = datetime.now() - t0\\n\\n        print(\\n            f\\\"Epoch : {e+1}/{epochs} Train_loss: {train_loss:.3f} Validation_loss: {validation_loss:.3f} Duration: {dt}\\\"\\n        )\\n\\n    return train_losses, validation_losses\\n\\n\\n# accuracy += torch.mean(equals.type(torch.FloatTensor))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def batch_gd(model, criterion, train_loader, validation_loader, epochs):\n",
    "    train_losses = np.zeros(epochs)\n",
    "    validation_losses = np.zeros(epochs)\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        model.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(inputs)\n",
    "\n",
    "            loss = criterion(output, targets)\n",
    "\n",
    "            train_loss.append(loss.item())  # torch to numpy world\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        \n",
    "        train_loss = np.mean(train_loss)\n",
    "\n",
    "        validation_loss = []\n",
    "\n",
    "        for inputs, targets in validation_loader:\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                output = model(inputs)\n",
    "\n",
    "                loss = criterion(output, targets)\n",
    "\n",
    "                validation_loss.append(loss.item())  # torch to numpy world\n",
    "        \n",
    "        \n",
    "        \n",
    "        validation_loss = np.mean(validation_loss)\n",
    "\n",
    "        train_losses[e] = train_loss\n",
    "        validation_losses[e] = validation_loss\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "\n",
    "        print(\n",
    "            f\"Epoch : {e+1}/{epochs} Train_loss: {train_loss:.3f} Validation_loss: {validation_loss:.3f} Duration: {dt}\"\n",
    "        )\n",
    "\n",
    "    return train_losses, validation_losses\n",
    " #accuracy += torch.mean(equals.type(torch.FloatTensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a1c86d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([8, 3, 224, 224])\n",
      "torch.Size([8])\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 96;\n                var nbb_unformatted_code = \"batch_size = 8\\ntrain_loader = torch.utils.data.DataLoader(\\n    dataset, batch_size=batch_size, sampler=train_sampler\\n)\\ntest_loader = torch.utils.data.DataLoader(\\n    dataset, batch_size=batch_size, sampler=test_sampler\\n)\\nvalidation_loader = torch.utils.data.DataLoader(\\n    dataset, batch_size=batch_size, sampler=validation_sampler\\n)\\n\\ndataiter = iter(train_loader)\\nimages, classes = dataiter.next()\\nprint(type(images))\\nprint(images.shape)\\nprint(classes.shape)\";\n                var nbb_formatted_code = \"batch_size = 8\\ntrain_loader = torch.utils.data.DataLoader(\\n    dataset, batch_size=batch_size, sampler=train_sampler\\n)\\ntest_loader = torch.utils.data.DataLoader(\\n    dataset, batch_size=batch_size, sampler=test_sampler\\n)\\nvalidation_loader = torch.utils.data.DataLoader(\\n    dataset, batch_size=batch_size, sampler=validation_sampler\\n)\\n\\ndataiter = iter(train_loader)\\nimages, classes = dataiter.next()\\nprint(type(images))\\nprint(images.shape)\\nprint(classes.shape)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, sampler=train_sampler\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, sampler=test_sampler\n",
    ")\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, sampler=validation_sampler\n",
    ")\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, classes = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(classes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3ac90cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/4 Train_loss: 1.539 Validation_loss: 1.241 Duration: 0:14:50.920072\n",
      "Epoch : 2/4 Train_loss: 1.060 Validation_loss: 0.936 Duration: 0:16:57.253714\n",
      "Epoch : 3/4 Train_loss: 0.913 Validation_loss: 0.943 Duration: 0:17:21.649750\n",
      "Epoch : 4/4 Train_loss: 0.806 Validation_loss: 0.871 Duration: 0:17:35.275104\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 97;\n                var nbb_unformatted_code = \"train_losses, validation_losses = batch_gd(\\n    model, criterion, train_loader, validation_loader, 4\\n)\";\n                var nbb_formatted_code = \"train_losses, validation_losses = batch_gd(\\n    model, criterion, train_loader, validation_loader, 4\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses, validation_losses = batch_gd(\n",
    "    model, criterion, train_loader, validation_loader, 4\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e343a784",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6f7ac81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 98;\n                var nbb_unformatted_code = \"torch.save(model.state_dict() , 'plant_disease_model_1.pt')\";\n                var nbb_formatted_code = \"torch.save(model.state_dict(), \\\"plant_disease_model_1.pt\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.save(model.state_dict() , 'plant_disease_model_1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db0cdbe",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1f2563e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CropDetectCNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=25088, out_features=39, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 99;\n                var nbb_unformatted_code = \"targets_size = 39\\nmodel = CropDetectCNN()\\nmodel.load_state_dict(torch.load(\\\"plant_disease_model_1.pt\\\"))\\nmodel.eval()\";\n                var nbb_formatted_code = \"targets_size = 39\\nmodel = CropDetectCNN()\\nmodel.load_state_dict(torch.load(\\\"plant_disease_model_1.pt\\\"))\\nmodel.eval()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets_size = 39\n",
    "model = CropDetectCNN()\n",
    "model.load_state_dict(torch.load(\"plant_disease_model_1.pt\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f0d731c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 100;\n                var nbb_unformatted_code = \"%matplotlib notebook\\n%matplotlib inline\";\n                var nbb_formatted_code = \"%matplotlib notebook\\n%matplotlib inline\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e7380",
   "metadata": {},
   "source": [
    "## Plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "98f7ca0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 101;\n                var nbb_unformatted_code = \"plt.plot(train_losses, label='train_loss')\\nplt.plot(validation_losses, label='validation_loss')\\nplt.xlabel('No of Epochs')\\nplt.ylabel('Loss')\\nplt.legend()\\nplt.show()\";\n                var nbb_formatted_code = \"plt.plot(train_losses, label=\\\"train_loss\\\")\\nplt.plot(validation_losses, label=\\\"validation_loss\\\")\\nplt.xlabel(\\\"No of Epochs\\\")\\nplt.ylabel(\\\"Loss\\\")\\nplt.legend()\\nplt.show()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='train_loss')\n",
    "plt.plot(validation_losses, label='validation_loss')\n",
    "plt.xlabel('No of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1894907",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "514f196f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.7635622880892486\n",
      "Validation Accuracy : 0.7518341307814992\n",
      "Test Accuracy : 0.7536058995770524\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 102;\n                var nbb_unformatted_code = \"def accuracy(loader):\\n    n_correct = 0\\n    n_total = 0\\n    model.eval()\\n    for inputs, targets in loader:\\n        inputs, targets = inputs.to(device), targets.to(device)\\n\\n        outputs = model(inputs)\\n\\n        _, predictions = torch.max(outputs, 1)\\n\\n        n_correct += (predictions == targets).sum().item()\\n        n_total += targets.shape[0]\\n\\n    acc = n_correct / n_total\\n    return acc\\n\\n\\ntrain_acc = accuracy(train_loader)\\nvalidation_acc = accuracy(validation_loader)\\ntest_acc = accuracy(test_loader)\\n\\nprint(\\n    f\\\"Train Accuracy : {train_acc}\\\\nValidation Accuracy : {validation_acc}\\\\nTest Accuracy : {test_acc}\\\"\\n)\";\n                var nbb_formatted_code = \"def accuracy(loader):\\n    n_correct = 0\\n    n_total = 0\\n    model.eval()\\n    for inputs, targets in loader:\\n        inputs, targets = inputs.to(device), targets.to(device)\\n\\n        outputs = model(inputs)\\n\\n        _, predictions = torch.max(outputs, 1)\\n\\n        n_correct += (predictions == targets).sum().item()\\n        n_total += targets.shape[0]\\n\\n    acc = n_correct / n_total\\n    return acc\\n\\n\\ntrain_acc = accuracy(train_loader)\\nvalidation_acc = accuracy(validation_loader)\\ntest_acc = accuracy(test_loader)\\n\\nprint(\\n    f\\\"Train Accuracy : {train_acc}\\\\nValidation Accuracy : {validation_acc}\\\\nTest Accuracy : {test_acc}\\\"\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def accuracy(loader):\n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    model.eval()\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        n_correct += (predictions == targets).sum().item()\n",
    "        n_total += targets.shape[0]\n",
    "\n",
    "    acc = n_correct / n_total\n",
    "    return acc\n",
    "\n",
    "\n",
    "train_acc = accuracy(train_loader)\n",
    "validation_acc = accuracy(validation_loader)\n",
    "test_acc = accuracy(test_loader)\n",
    "\n",
    "print(\n",
    "    f\"Train Accuracy : {train_acc}\\nValidation Accuracy : {validation_acc}\\nTest Accuracy : {test_acc}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd05e869",
   "metadata": {},
   "source": [
    "## Single Image prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f76e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.class_to_idx = dataset.class_to_idx\n",
    "model.class_to_idx.items()\n",
    "\n",
    "# transform_index_to_disease = dataset.class_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76556e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_index_to_disease = dict(\n",
    "    [(value, key) for key, value in model.class_to_idx.items()]\n",
    ")  # reverse the index\n",
    "transform_index_to_disease.items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "78902155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 105;\n                var nbb_unformatted_code = \"from PIL import Image\\nimport torchvision.transforms.functional as TF\\n\\ndef single_prediction(image_path):\\n    image = Image.open(image_path)\\n    image = image.resize((224, 224))\\n    input_data = TF.to_tensor(image)\\n    input_data = input_data.view((-1, 3, 224, 224))\\n    output = model(input_data)\\n    #top_p, top_cl = ps.topk(5, dim=1)\\n    \\n    output = output.detach().numpy()\\n    \\n    index = np.argmax(output)\\n    \\n    \\n    print(\\\"Original : \\\", image_path.split(\\\"/\\\")[-2])\\n    \\n    print(f\\\"Prediction of our model: \\\", transform_index_to_disease[index])\\n    \\n    return image, output\\n\\n    \";\n                var nbb_formatted_code = \"from PIL import Image\\nimport torchvision.transforms.functional as TF\\n\\n\\ndef single_prediction(image_path):\\n    image = Image.open(image_path)\\n    image = image.resize((224, 224))\\n    input_data = TF.to_tensor(image)\\n    input_data = input_data.view((-1, 3, 224, 224))\\n    output = model(input_data)\\n    # top_p, top_cl = ps.topk(5, dim=1)\\n\\n    output = output.detach().numpy()\\n\\n    index = np.argmax(output)\\n\\n    print(\\\"Original : \\\", image_path.split(\\\"/\\\")[-2])\\n\\n    print(f\\\"Prediction of our model: \\\", transform_index_to_disease[index])\\n\\n    return image, output\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "def single_prediction(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))\n",
    "    input_data = TF.to_tensor(image)\n",
    "    input_data = input_data.view((-1, 3, 224, 224))\n",
    "    output = model(input_data)\n",
    "    #top_p, top_cl = ps.topk(5, dim=1)\n",
    "    \n",
    "    output = output.detach().numpy()\n",
    "    \n",
    "    index = np.argmax(output)\n",
    "    \n",
    "    \n",
    "    print(\"Original : \", image_path.split(\"/\")[-2])\n",
    "    \n",
    "    print(f\"Prediction of our model: \", transform_index_to_disease[index])\n",
    "    \n",
    "    return image, output\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48675f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "image, pred = single_prediction(\"\")\n",
    "\n",
    "\n",
    "probabilities = softmax(pred)\n",
    "\n",
    "print(probabilities)\n",
    "\n",
    "probabilities.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3fcfd233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 115;\n                var nbb_unformatted_code = \"from PIL import Image\\nimport numpy as np\\n# Plot the image\\n\\ndef imshow(image):\\n    fig, ax = plt.subplots()\\n\\n    # convert the shape from (3, 256, 256) to (256, 256, 3)\\n    image = image.transpose(0, 1, 2)\\n    ax.imshow(image)\\n    ax.set_xticklabels('')\\n    ax.set_yticklabels('')\\n\\n    return ax\\n\\n\\ndef process_image(image_path):\\n\\n    test_transform = transforms.Compose([transforms.RandomResizedCrop(224),\\n                                         transforms.ToTensor()])\\n    im = Image.open(image_path)\\n    imshow(np.array(im))\\n    im = test_transform(im)\\n    \\n    return im\";\n                var nbb_formatted_code = \"from PIL import Image\\nimport numpy as np\\n\\n# Plot the image\\n\\n\\ndef imshow(image):\\n    fig, ax = plt.subplots()\\n\\n    # convert the shape from (3, 256, 256) to (256, 256, 3)\\n    image = image.transpose(0, 1, 2)\\n    ax.imshow(image)\\n    ax.set_xticklabels(\\\"\\\")\\n    ax.set_yticklabels(\\\"\\\")\\n\\n    return ax\\n\\n\\ndef process_image(image_path):\\n\\n    test_transform = transforms.Compose(\\n        [transforms.RandomResizedCrop(224), transforms.ToTensor()]\\n    )\\n    im = Image.open(image_path)\\n    imshow(np.array(im))\\n    im = test_transform(im)\\n\\n    return im\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "# Plot the image\n",
    "\n",
    "def imshow(image):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # convert the shape from (3, 256, 256) to (256, 256, 3)\n",
    "    image = image.transpose(0, 1, 2)\n",
    "    ax.imshow(image)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def process_image(image_path):\n",
    "\n",
    "    test_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                         transforms.ToTensor()])\n",
    "    im = Image.open(image_path)\n",
    "    imshow(np.array(im))\n",
    "    im = test_transform(im)\n",
    "    \n",
    "    return im\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "65f8ab94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 116;\n                var nbb_unformatted_code = \"def predict(image, model):\\n    # we have to process the image as we did while training the others\\n    image = process_image(image)\\n\\n    #returns a new tensor with a given dimension\\n    image_input = image.unsqueeze(0)\\n\\n    # Convert the image to either gpu|cpu\\n    image_input.to(device)\\n\\n    # Pass the image through the model\\n    outputs = model(image_input)\\n    \\n    # Softmax on our output -> Transforming prediction scores into probabilities\\n    m = nn.Softmax(dim=1)\\n    proba = m(outputs)\\n        \\n    # return the top 5 most predicted classes\\n    top_p, top_cls = proba.topk(5, dim=1)\\n        \\n    # convert to numpy, then to list\\n    top_cls = top_cls.detach().numpy().tolist()[0]\\n\\n    # covert indices to classes\\n    idx_to_class = {v: k for k, v in model.class_to_idx.items()}\\n\\n    top_cls = [idx_to_class[top_class] for top_class in top_cls]\\n\\n    return top_p, top_cls\";\n                var nbb_formatted_code = \"def predict(image, model):\\n    # we have to process the image as we did while training the others\\n    image = process_image(image)\\n\\n    # returns a new tensor with a given dimension\\n    image_input = image.unsqueeze(0)\\n\\n    # Convert the image to either gpu|cpu\\n    image_input.to(device)\\n\\n    # Pass the image through the model\\n    outputs = model(image_input)\\n\\n    # Softmax on our output -> Transforming prediction scores into probabilities\\n    m = nn.Softmax(dim=1)\\n    proba = m(outputs)\\n\\n    # return the top 5 most predicted classes\\n    top_p, top_cls = proba.topk(5, dim=1)\\n\\n    # convert to numpy, then to list\\n    top_cls = top_cls.detach().numpy().tolist()[0]\\n\\n    # covert indices to classes\\n    idx_to_class = {v: k for k, v in model.class_to_idx.items()}\\n\\n    top_cls = [idx_to_class[top_class] for top_class in top_cls]\\n\\n    return top_p, top_cls\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict(image, model):\n",
    "    # we have to process the image as we did while training the others\n",
    "    image = process_image(image)\n",
    "\n",
    "    #returns a new tensor with a given dimension\n",
    "    image_input = image.unsqueeze(0)\n",
    "\n",
    "    # Convert the image to either gpu|cpu\n",
    "    image_input.to(device)\n",
    "\n",
    "    # Pass the image through the model\n",
    "    outputs = model(image_input)\n",
    "    \n",
    "    # Softmax on our output -> Transforming prediction scores into probabilities\n",
    "    m = nn.Softmax(dim=1)\n",
    "    proba = m(outputs)\n",
    "        \n",
    "    # return the top 5 most predicted classes\n",
    "    top_p, top_cls = proba.topk(5, dim=1)\n",
    "        \n",
    "    # convert to numpy, then to list\n",
    "    top_cls = top_cls.detach().numpy().tolist()[0]\n",
    "\n",
    "    # covert indices to classes\n",
    "    idx_to_class = {v: k for k, v in model.class_to_idx.items()}\n",
    "\n",
    "    top_cls = [idx_to_class[top_class] for top_class in top_cls]\n",
    "\n",
    "    return top_p, top_cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fa9a5319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 117;\n                var nbb_unformatted_code = \"import seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n\\ndef plot_solution(image_path, ps, classes):\\n    \\n    fig = plt.figure(figsize=(6, 10))\\n    image = process_image(image_path)\\n    plt.subplot(2, 1, 2)\\n    image\\n    sns.barplot(x=ps, y=classes, color=sns.color_palette()[2])\\n    fig.show()\";\n                var nbb_formatted_code = \"import seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n\\ndef plot_solution(image_path, ps, classes):\\n\\n    fig = plt.figure(figsize=(6, 10))\\n    image = process_image(image_path)\\n    plt.subplot(2, 1, 2)\\n    image\\n    sns.barplot(x=ps, y=classes, color=sns.color_palette()[2])\\n    fig.show()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_solution(image_path, ps, classes):\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 10))\n",
    "    image = process_image(image_path)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    image\n",
    "    sns.barplot(x=ps, y=classes, color=sns.color_palette()[2])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fcf6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "image = \"\"\n",
    "\n",
    "results = []\n",
    "for i in range(100):\n",
    "    ps, classes = predict(image, model)\n",
    "    ps = ps.detach().numpy().tolist()[0]\n",
    "    results.append(classes[0])\n",
    "\n",
    "\n",
    "print(f\"Results for 100 predictions of a Grape___Black_rot: \",\n",
    "      Counter(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f769025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "image = \"\"\n",
    "\n",
    "results=[]\n",
    "# for i in range(100):\n",
    "#     ps, classes = predict(image, model)\n",
    "#     ps = ps.detach().numpy().tolist()[0]\n",
    "#     results.append(classes[0])\n",
    "ps, classes = predict(image, model)\n",
    "ps = ps.detach().numpy().tolist()[0]\n",
    "\n",
    "plot_solution(image, ps, classes)\n",
    "\n",
    "#print(f\"Results for 1 predictions of a Black rot disease on an apple leaf: \", Counter(results))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"\"\n",
    "ps, classes = predict(image, model)\n",
    "ps = ps.detach().numpy().tolist()[0]\n",
    "\n",
    "print(ps)\n",
    "print(classes)\n",
    "\n",
    "plot_solution(image, ps, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f3f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"\"\n",
    "ps, classes = predict(image, model)\n",
    "ps = ps.detach().numpy().tolist()[0]\n",
    "\n",
    "print(ps)\n",
    "print(classes)\n",
    "\n",
    "plot_solution(image, ps, classes)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "983a0918417c57fb24a0ef4da64bfa0af9197eebebc9df36ea061540d32c237d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('DataB': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
